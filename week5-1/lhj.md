# Neural Networks : Learning
## Cost Function and Backpropagation(ì—­ì „íŒŒ)
### Cost Function
#### Neural Network
- L = total num of layers in network
- s_l = num of units(not counting bias unit) in layer l
- k = num of units in output layerRecent resurgence : State-of-the-art technique for many applications

#### Classification
- Binary classification
  - y = 0 or 1, 1output unit
- Multi-class classification (K calsses)
  - Kê°œì˜ ë¶„ë¦¬ëœ í´ë˜ìŠ¤ë“¤ì—ëŒ€í•´ ê°ê°ì˜ Output unitì„ ê°€ì§
  - K output units
  - ì‹¤ìˆ˜ê°€ ì•„ë‹Œ Kì°¨ì˜ Output Vector h_theta(x)
  - KëŠ” ë°”ì´ë„ˆë¦¬ê°€ ì•„ë‹ˆë¯€ë¡œ k >= 3 ë§Œì¡±

#### Cost Function
- Neural Networkì—ì„œ ì‚¬ìš©í•  Cost Functionì€ Logistic Regressionì˜ ë¹„ìš©í•¨ìˆ˜ë¥¼ ì¼ë°˜í™”ì‹œí‚¨ í•¨ìˆ˜
- Kê°œì˜ Outputì„ ê°€ì§
- h_theta(x)ëŠ” kì°¨ì›ì˜ í–‰ë ¹, k_theta(x)_iëŠ” í–‰ë ¬ì˜ ië²ˆì§¸ ìš”ì†Œ
- ê°ê°ì˜ Output Unit h_theta(x)ë¥¼ ëª¨ë‘ ë”í•œê²ƒ

- Suppose we want to try to minimize J(\Theta)J(Î˜) as a function of \ThetaÎ˜, using one of the advanced optimization methods (fminunc, conjugate gradient, BFGS, L-BFGS, etc.). What do we need to supply code to compute (as a function of \ThetaÎ˜)?
    - J(Î˜) and the (partial) derivative terms âˆ‚/âˆ‚ğœƒ_ij^(l) for every i,j,l

- the double sum simply adds up the logistic regression costs calculated for each cell in the output layer
- the triple sum simply adds up the squares of all the individual Î˜s in the entire network.
- the i in the triple sum does not refer to training example i

### BackPropagation Algorithm(ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜)
- J(Î˜)ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë§¤ê°œë³€ìˆ˜ Î˜ë¥¼ ì°¾ì•„ì•¼í•¨
  - ê·¸ëŸ¬ê¸° ìœ„í•´ ê²½ì‚¬ë„í•˜ê°•ë²•ì´ë‚˜ ë‹¤ë¥¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ì•¼í•¨
  - J(Î˜)ë¥¼ êµ¬í•˜ê³  ì´ë¥¼ í¸ë¯¸ë¶„í•˜ëŠ” ê²ƒì„ êµ¬í•´ì•¼í•¨
  - Î˜_ij^(l) ì€ ì‹¤ìˆ˜ ì„
- Cost Functionì„ ìµœì†Œí™” ì‹œí‚¤ëŠ” ì•Œê³ ë¦¬ì¦˜

- Given training set {(x(1), y^(1)â‹¯(x^(m), y^(m)))}
  - set Î”_i,j^(l) := 0 for all (l,i,j)

#### Gradient Computation
- ğ›¿_j(4) = a_j^(4) - y_j
- ğ›¿^(3) = (Î˜^(3))^Tğ›¿^(4). * g'(z^(3)) // g'(z^(3)) : a^(3) .* (1-a^(3))
- ğ›¿^(2) = (Î˜^(2))^Tğ›¿^(3). * g'(z^(2)) // g'(z^(2)): a^(2) .* (1-a^(2))
- Suppose you have two training examples (x^{(1)}, y^{(1)})(x (1),y (1)) and (x^{(2)}, y^{(2)})(x(2),y(2)). Which of the following is a correct sequence of operations for computing the gradient? (Below, FP = forward propagation, BP = back propagation).
  - FP using x^{(1)}x(1) followed by BP using y^{(1)}y(1). Then FP using x^{(2)}x(2) followed by BP using y^{(2)}y(2).

### Backpropagation Intuition


## Backpropagation in Practice

### Implementation Note: Unrolling Parameters
### Gradient Checking
- ì—­ì „íŒŒë¥¼ ì´ìš©í•˜ì—¬ ë§ì€ ë²„ê·¸ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ Gradient Descentë‚˜ ë‹¤ë¥¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì— ì ìš©í•˜ë©´ Cost Functionì´ ì˜ ê°ì†Œí•˜ì—¬ ë¬¸ì œê°€ ì—†ëŠ”ê±°ì„œì²  ë³´ì¼ ìˆ˜ ìˆë‹¤.
- ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ëŠ” Bugë¥¼ ë°œê²¬í•˜ì§€ ëª»í•  í™•ë¥ ì´ ì¡´ì¬
- ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Gradient Checkingì„ Modelì— ì ìš©í•˜ì—¬ ê²€ì‚¬í•˜ëŠ”ê²ƒì´ í•„ìš”í•¨

- What is the main reason that we use the backpropagation algorithm rather than the numerical gradient computation method during learning?
  - The numerical gradient algorithm is very slow.

### Random Initialization
- Optimization Algorithm ì„ ìœ„í•œ ì´ˆê¸° thetaê°’ ì§€ì •
- ì´ˆê¸° theta = 0 ì´ë©´ Logistic Regressionì—ì„œë§Œ ì˜ ì‘ë™í•˜ê³  Neural Network ì—ì„œëŠ” ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ì§€ ì•ŠìŒ

- Symmetry Problem
  - ëª¨ë“  i, j, Lì— ëŒ€í•˜ì—¬ theta_ij^(l) = 0 ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆë‹¤ê³  ê°€ì •
    - ê²°ê³¼ê°’
      - theta_01^1 = theta_02^2
      - a_1^(2) = a_2^(2)
      - ğ›¿_1^(2) = ğ›¿_2^(2)
      - âˆ‚/âˆ‚ğœƒ_01^1*J(ğœƒ) = âˆ‚/âˆ‚ğœƒ_02^2 J(ğœƒ)
  - ë§¤ë²ˆì˜ ì—…ë°ì´íŠ¸ê°€ ëë‚ ë–„ë§ˆë‹¤ parameter thetaê°€ ê°™ì•„ì§€ê³ , Layerì˜ Featureë„ ê°™ì€ ê°’ì„ ê°–ê²Œ ëœë‹¤. ì´ëŸ° ìƒí™©ì´ ì§€ì†ë˜ë©´ Hidden Unitì´ ë§ì€ ê²½ìš°ë¼ í•˜ë”ë¼ë„ ëª¨ë“  Hidden Unitì´ ê°™ì€ Featureë¥¼ ê°€ì§€ë©° ê²°êµ­ í•˜ë‚˜ì˜ Featureë¥¼ ê°–ëŠ” Neural Networkê°€ ë˜ëŠ” ë¬¸ì œ
  - Random Initializationì„ ì‚¬ìš©í•˜ì—¬ Symeetry Breakingì„ ìˆ˜í–‰
  - Initializer each Î˜_ij^(l) to a random value in [âˆ’ğœ–, ğœ–]

- Consider this procedure for initializing the parameters of a neural network: Pick a random number r = rand(1,1) * (2 * INIT_EPSILON) - INIT_EPSILON Set Î˜_ij^(l)=r for all i,j,li,j,l. Does this work?
  - No, because this fails to break symmetry.

- If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11.
  - Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
  - Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
  - Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON;

### Putting it Together
#### Training a neural network
- L = total num of layers in network num of input units : Featureë“¤ì˜ ê°¯ìˆ˜ (x^(i)ì˜ ì°¨ìˆ˜)
- Num of output units: Classë“¤ì˜ ê°œìˆ˜
- Hidden Layer: Default = 1 but if hidden layer > 1 , have same num of hidden units in every layer is better

- Hidden Unitì˜ ìˆ˜ëŠ” ë§ìœ¼ë©´ ë§ì„ìˆ˜ë¡ ì¢‹ìŒ
- Hidden Layerê°€ ê°™ì€ ìˆ˜ì˜ Hidden Unitì˜ ê°œìˆ˜ë¥¼ ì§€ë‹Œë‹¤ë©´ ì„±ëŠ¥ì´ ì¢‹ìŒ
- Hidden Unitì˜ ê°œìˆ˜ëŠ” Input unitê³¼ output unitë“±ì„ ê³ ë ¤í•˜ì—¬ ìƒëŒ€ì ìœ¼ë¡œ ì„ ì •

1. Randomly initializer weights
2. implement forward propagation to get h_thata(x^(i)) for any x^(i)
3. Implement code to compute cost function J(theta)
4. Implement backpropagation to compute partial derivatives âˆ‚/âˆ‚ğœƒ_jk^(l)*J(ğœƒ)
5. Use gradient checking to compare âˆ‚/âˆ‚ğœƒ J(ğœƒ) comuted using backprop vs using numerical extimate of gradient of J(ğœƒ), Then disable gradient checking code
6. User Gradient Descent or advanced optimization method with backprop to ry to minimize J(ğœƒ) as a function of parameters ğœƒ

1. ğœƒë¥¼ 0ì— ê·¼ì‚¬í•œ ì‘ì€ ê°’ì„ ì´ˆê¸°í™”
2. ì„ì˜ì˜ xì— ëŒ€í•œ h_ğœƒ(x^(i))ë¥¼ êµ¬í•˜ëŠ” Forward Propagationê³¼ J(ğœƒ)ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ, ê·¸ë¦¬ê³  Partial derivativesë¥¼ êµ¬í•˜ê¸° ìœ„í•œ VackPropagation ì½”ë“œ êµ¬í˜„
3. ëª¨ë“  Training Example(for i=1:m)ì— ëŒ€í•˜ì—¬ í•™ìŠµ
4. ê·¸ì•ˆì—ì„œ FP BPê°€ ìˆ˜í–‰ë˜ì–´ ğ‘^(ğ‘™),ğ›¿^(ğ‘™),Î”^(ğ‘™) ê°€ êµ¬í•´ì§
5. BPê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ Gradient Checking ìˆ˜í–‰ í›„ ì •ìƒì‘ë™ì‹œ êº¼ì¤Œ
6. ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©í•˜ì—¬ ìµœì†Œ J(ğœƒ)ê°’ êµ¬í•¨
7. J(ğœƒ)ê°€ Non-Convexë©´ Local Optimaë¡œ ìˆ˜ë ´í• ìˆ˜ ìˆì§€ë§Œ ê·¸ ê°’ì€ Global Optimaì— ê·¼ì ‘í•œ ìƒë‹¹íˆ ì¢‹ì€ ê°’ì„

- Suppose you are using gradient descent together with backpropagation to try to minimize J(Î˜) as a function of Î˜. Which of the following would be a useful step for verifying that the learning algorithm is running correctly?
  - Plot J(Î˜) as a function of the number of iterations and make sure it is decreasing (or at least non-increasing) with every iteration.


#### Gradient Descent for neural network
- 2ê°œì˜ Parameterê°’ì„ ê°–ëŠ” Neural Networkì— ëŒ€í•œ Gradient Descent ì•Œê³ ë¦¬ì¦˜ì´ ìˆ˜í–‰ë˜ì—ˆì„ ì‹œ, ì´ ì•Œê³ ë¦¬ì¦˜ì€ Random ìœ„ì¹˜ì—ì„œ ì‹œì‘í•˜ì—¬ ë‚´ë¦¬ë§‰ê¸¸ìœ¼ ë”°ë¼ê°€ë©° Optimaë¥¼ ì°¾ëŠ” ê²ƒ
- ì—¬ê¸°ì„œ BPê°€ í•˜ëŠ” ì—­í• ì€ Gradient Descentê°€ ë‚´ë ¤ê°€ëŠ” ë°©í–¥ì„ ì²´í¬í•˜ëŠ” ê²ƒì„
